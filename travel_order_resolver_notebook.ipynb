{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46425e2",
   "metadata": {},
   "source": [
    "\n",
    "# Travel Order Resolver\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Ce projet vise à développer un modèle NLP pour résoudre les ordres de voyage. Nous allons utiliser des modèles basés sur le langage naturel, tels que **CamemBERT**, pour extraire les entités des ordres de voyage. Ces entités incluent les villes de départ et d'arrivée.\n",
    "\n",
    "Les modèles seront évalués en fonction de la précision de l'extraction des entités, du score F1, et d'autres métriques pertinentes.\n",
    "\n",
    "<style>\n",
    "h1 {color: navy;}\n",
    "h2 {color: navy;}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79fa53",
   "metadata": {},
   "source": [
    "\n",
    "## Structure du Dataset\n",
    "\n",
    "Le dataset est composé de phrases contenant des ordres de voyage. Chaque phrase contient :\n",
    "- Le texte de la phrase\n",
    "- La ville de départ\n",
    "- La ville d'arrivée\n",
    "- Un label indiquant si la phrase est valide ou non\n",
    "\n",
    "Ces données sont utilisées pour entraîner et évaluer le modèle de reconnaissance d'entités nommées (NER).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24425756",
   "metadata": {},
   "source": [
    "\n",
    "## Préparation des Données avec DataProcessor\n",
    "\n",
    "La classe **DataProcessor** est utilisée pour préparer le dataset. Elle permet de charger et de filtrer les phrases, d'extraire les villes de départ et d'arrivée, et de formater les données pour l'entraînement.\n",
    "\n",
    "```python\n",
    "class DataProcessor:\n",
    "    def load_dataset(self, filepath):\n",
    "        # Charger les données à partir du fichier CSV\n",
    "        pass\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        # Préparation et tokenization des données\n",
    "        pass\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385f6e6",
   "metadata": {},
   "source": [
    "\n",
    "## Modèle CamemBERT pour la reconnaissance d'entités nommées (NER)\n",
    "\n",
    "Le modèle **CamemBERT** est un modèle de type transformateur pré-entraîné sur des tâches de traitement de la langue française. Pour notre tâche, il est fine-tuné pour reconnaître les entités nommées, en particulier les villes de départ et d'arrivée.\n",
    "\n",
    "### Construction du modèle\n",
    "\n",
    "Le modèle est basé sur la bibliothèque `Transformers` de Hugging Face. Voici comment nous le configurons et l'entraînons :\n",
    "\n",
    "```python\n",
    "from transformers import CamembertForTokenClassification, CamembertTokenizerFast, Trainer, TrainingArguments\n",
    "\n",
    "model = CamembertForTokenClassification.from_pretrained(\"camembert-base\", num_labels=3)\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Arguments d'entraînement\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e353a08",
   "metadata": {},
   "source": [
    "\n",
    "## Évaluation du Modèle\n",
    "\n",
    "Le modèle est évalué en utilisant des métriques telles que :\n",
    "- **Précision** : Le pourcentage de prédictions correctes.\n",
    "- **Rappel** : La capacité du modèle à identifier toutes les entités pertinentes.\n",
    "- **Score F1** : La moyenne harmonique de la précision et du rappel.\n",
    "\n",
    "Nous utilisons également une matrice de confusion pour analyser les faux positifs et les faux négatifs.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_true = [1, 0, 1]  # Exemples de labels réels\n",
    "y_pred = [1, 0, 0]  # Exemples de prédictions du modèle\n",
    "\n",
    "# Affichage du rapport de classification\n",
    "print(classification_report(y_true, y_pred, target_names=[\"O\", \"B-city\", \"I-city\"]))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a44839",
   "metadata": {},
   "source": [
    "\n",
    "## Résultats du Modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb7cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Chargement des résultats du modèle NER\n",
    "with open(\"ner_results.json\", \"r\") as file:\n",
    "    ner_results = json.load(file)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"## Précision: {}\".format(ner_results['precision']))\n",
    "print(\"## Rappel: {}\".format(ner_results['recall']))\n",
    "print(\"## Score F1: {}\".format(ner_results['f1']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8943831",
   "metadata": {},
   "source": [
    "\n",
    "### Graphique des Résultats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a0d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Chargement des résultats\n",
    "with open(\"ner_results.json\", \"r\") as file:\n",
    "    ner_results = json.load(file)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = np.array(ner_results['confusion_matrix'])\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['O', 'B-city', 'I-city'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Matrice de Confusion')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c0983",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "Le modèle **CamemBERT** fine-tuné pour la reconnaissance d'entités nommées montre une bonne performance pour identifier les villes de départ et d'arrivée dans les ordres de voyage. Il peut encore être amélioré en augmentant le volume de données et en ajustant les hyperparamètres.\n",
    "\n",
    "### Améliorations futures\n",
    "- Augmenter la taille du dataset\n",
    "- Optimiser les hyperparamètres pour une meilleure précision\n",
    "- Utiliser des techniques d'augmentation de données\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
